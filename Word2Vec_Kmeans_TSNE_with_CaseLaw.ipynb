{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Court of Appeals for the Seventh Circuit Analysis\n",
    "##Raw data is available from: https://www.courtlistener.com\n",
    "##Analysis was done by looking at over 40k documents from the Seventh Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "import csv\n",
    "import string\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code inspired/borrowed from:\n",
    "    #https://www.kaggle.com/c/word2vec-nlp-tutorial\n",
    "    #http://brandonrose.org/clustering\n",
    "    #http://opensource.datacratic.com/mtlpy50/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load nltk's English stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def cleanraj( review, remove_stopwords=False ):\n",
    "    #Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
    "\n",
    "    #Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "\n",
    "    #Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        #stops = set(stopwords.words(\"english\"))\n",
    "        #stops.update(['test'])\n",
    "        #words = [w for w in words if not w in stops]\n",
    "        words = [w for w in words if not w in stopwords]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Script to consolidate all the plain text parts\n",
    "%cd /Users/rajivshah/Documents/Documents/Projects/SeventhCircuit/data/ca7\n",
    "case =[]\n",
    "data=[]\n",
    "text=[]\n",
    "content=[]\n",
    "sentences=[]\n",
    "test=[]\n",
    "import glob\n",
    "files = glob.glob( '*.json' )\n",
    "\n",
    "with open( 'result.txt', 'a' ) as result:\n",
    "    for file_ in files:\n",
    "        with open( file_, 'r' ) as infile:\n",
    "            text = infile.read().decode('utf-8','replace')\n",
    "            data = json.loads(text)\n",
    "            case = data['plain_text']\n",
    "            tokens = nltk.word_tokenize(case)\n",
    "            for i in tokens:\n",
    "                temp = cleanraj(i,remove_stopwords=True)\n",
    "                if len(temp) != 0:\n",
    "                    test.append(temp)\n",
    "            #result.write(\"%s|\" % test) ##If you want to save the results of your work\n",
    "            content.append(test)\n",
    "            test = []\n",
    "result.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##If you read it from a file, optional\n",
    "#content=[]\n",
    "#with open('result.txt', 'r') as f:\n",
    "#    content = f.readline().split('|')\n",
    "#f.closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Parse the content into sentences\n",
    "sentences = []  # Initialize an empty list of sentences\n",
    "for i in content:\n",
    "    sentences += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sentences)\n",
    "# 7063681"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##WORD2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time model = gensim.models.Word2Vec(sentences, min_count=400)\n",
    "print(model)\n",
    "len(model.syn0)\n",
    "model.most_similar(\"court\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Keep model in memory\n",
    "model.init_sims(replace=True)\n",
    "#Save Model\n",
    "model_name=\"first-3526\"\n",
    "#model.save(model_name)\n",
    "#model.save_word2vec_format(model_name + '-b.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2vec_dict={}\n",
    "for i in model.vocab.keys():\n",
    "    try:\n",
    "        word2vec_dict[i]=model[i]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(word2vec_dict.values(), dtype = np.float64)\n",
    "Xmodel = TSNE(n_components=2, verbose=2, n_iter=200)\n",
    "t = Xmodel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##KMeans Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    "\n",
    "# Set \"k\" (num_clusters) \n",
    "word_vectors = model.syn0\n",
    "num_clusters = 20\n",
    "\n",
    "# Initalize a k-means object and use it to extract centroids\n",
    "kmeans_clustering = KMeans( n_clusters = num_clusters )\n",
    "idx = kmeans_clustering.fit_predict( word_vectors )\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print \"Time taken for K Means clustering: \", elapsed, \"seconds.\"\n",
    "\n",
    "word_centroid_map=dict(zip(model.index2word,idx))\n",
    "\n",
    "for cluster in xrange(0,num_clusters):\n",
    "    print (\"\\nCluster %d\" % cluster)\n",
    "    words = []\n",
    "    for i in xrange(0,len(word_centroid_map.values())):\n",
    "        if (word_centroid_map.values()[i] == cluster):\n",
    "            words.append(word_centroid_map.keys()[i])\n",
    "    print (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Create plot in matplotlib - BORING\n",
    "\n",
    "#from pylab import rcParams\n",
    "#rcParams['figure.figsize']=15,15\n",
    "\n",
    "#Creates plot\n",
    "#N = len(word2vec_dict)\n",
    "#labels=[word2vec_dict.keys()[i] for i in N]\n",
    "#for i in range(0,N):\n",
    "#    str = (word2vec_dict.keys()[i])\n",
    "#    y = word_centroid_map[str]\n",
    "#    labelnum.append(y)\n",
    "\n",
    "#plt.scatter(t[:, 0], t[:, 1])\n",
    "#index=0\n",
    "#for label, x, y in zip(labels, t[:, 0], t[:, 1]):\n",
    "#    plt.annotate(\n",
    "#        label, \n",
    "#        xy = (x, y), xytext = (-20, 20),\n",
    "#        textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "#        bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
    "#        arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bokeh\n",
    "from bokeh.plotting import *\n",
    "from bokeh.models import HoverTool \n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Sets up labels and colors\n",
    "N = len(word2vec_dict)\n",
    "labels=[word2vec_dict.keys()[i] for i in range(N)]\n",
    "labelnum=[]\n",
    "temp =[]\n",
    "str=[]\n",
    "for i in range(0,N):\n",
    "    str = (word2vec_dict.keys()[i])\n",
    "    temp = word_centroid_map[str]\n",
    "    labelnum.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Label Colors\n",
    "LABEL_COLOR_MAP = {0 : 'steelblue',\n",
    "                   1 : 'aqua',\n",
    "                   2 : 'black',\n",
    "                   3 : 'brown',\n",
    "                   4 : 'coral',\n",
    "                   5 : 'darkgray',\n",
    "                   6 : 'gold',\n",
    "                   7 : 'indianred',\n",
    "                   8 : 'lemonchiffon',\n",
    "                   9 : 'maroon',\n",
    "                   10 : 'olivedrab',\n",
    "                   11 : 'pink',\n",
    "                   12 : 'plum',\n",
    "                   13 : 'steelblue',\n",
    "                   14 : 'k',\n",
    "                   15 : 'silver',\n",
    "                   16 : 'skyblue',\n",
    "                   17 : 'tan',\n",
    "                   18 : 'teal',\n",
    "                    19: 'yellowgreen'\n",
    "                   }\n",
    "\n",
    "label_color = [LABEL_COLOR_MAP[l] for l in labelnum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Creates tsne visualization\n",
    "output_file(\"tsne.html\")\n",
    "p = figure(plot_width=700, plot_height=700, title=\"Court of Appeals for the Seventh Circuit\",\n",
    "       tools=\"pan,wheel_zoom,box_zoom,reset,hover,previewsave\",\n",
    "       x_axis_type=None, y_axis_type=None, min_border=1)\n",
    "source = ColumnDataSource({\"names\":labels})\n",
    "p.scatter(t[:,0], t[:,1], marker=\"circle\",source=source,\n",
    "          color=label_color,\n",
    "           # line_color=\"#6666ee\", fill_color=\"#ee6666\", \n",
    "          fill_alpha=0.5, size=12).select(dict(type=HoverTool)).tooltips = {\"/r/\":\"@names\"}\n",
    "#p.text(t[:,0], t[:,1], labels, text_font_size=\"9pt\", text_align=\"center\", text_baseline=\"middle\")\n",
    "save(p)\n",
    "#show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
